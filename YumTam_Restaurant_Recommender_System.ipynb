{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82530497",
      "metadata": {
        "id": "82530497",
        "outputId": "0e1a84a5-3f78-4f28-9870-e17bf09b3b7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joash\\AppData\\Local\\Temp\\ipykernel_12740\\3260248562.py:7: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_full = pd.read_csv(train_full_path)\n",
            "C:\\Users\\Joash\\AppData\\Local\\Temp\\ipykernel_12740\\3260248562.py:8: DtypeWarning: Columns (0,1,4,5,7,14,19,20,23,28,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,60,61,62,65,66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  test_full = pd.read_csv(test_full_path)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "train_full_path = \"C:/Users/Joash/Desktop/recommender/train_full.csv\"\n",
        "test_full_path = \"C:/Users/Joash/Desktop/recommender/test_full.csv\"\n",
        "\n",
        "train_full = pd.read_csv(train_full_path)\n",
        "test_full = pd.read_csv(test_full_path)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4bc223d",
      "metadata": {
        "id": "a4bc223d",
        "outputId": "e97fe80e-afda-4ab9-9c2e-2534635558a1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>status_x</th>\n",
              "      <th>verified_x</th>\n",
              "      <th>created_at_x</th>\n",
              "      <th>updated_at_x</th>\n",
              "      <th>location_number</th>\n",
              "      <th>location_type</th>\n",
              "      <th>latitude_x</th>\n",
              "      <th>longitude_x</th>\n",
              "      <th>...</th>\n",
              "      <th>country_id</th>\n",
              "      <th>city_id</th>\n",
              "      <th>created_at_y</th>\n",
              "      <th>updated_at_y</th>\n",
              "      <th>device_type</th>\n",
              "      <th>display_orders</th>\n",
              "      <th>location_number_obj</th>\n",
              "      <th>id_obj</th>\n",
              "      <th>CID X LOC_NUM X VENDOR</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCHWPBT</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>0</td>\n",
              "      <td>Work</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-01-30 14:42:04</td>\n",
              "      <td>2020-04-07 15:12:43</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>TCHWPBT X 0 X 4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCHWPBT</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>0</td>\n",
              "      <td>Work</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-03 12:32:06</td>\n",
              "      <td>2020-04-05 20:46:03</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>TCHWPBT X 0 X 13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCHWPBT</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>0</td>\n",
              "      <td>Work</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-04 22:28:22</td>\n",
              "      <td>2020-04-07 16:35:55</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>TCHWPBT X 0 X 20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCHWPBT</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>0</td>\n",
              "      <td>Work</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-06 19:20:48</td>\n",
              "      <td>2020-04-02 00:56:17</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>TCHWPBT X 0 X 23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCHWPBT</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>2018-02-07 19:16:23</td>\n",
              "      <td>0</td>\n",
              "      <td>Work</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-17 22:12:38</td>\n",
              "      <td>2020-04-05 15:57:41</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>TCHWPBT X 0 X 28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 73 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  customer_id gender  status_x  verified_x         created_at_x  \\\n",
              "0     TCHWPBT   Male         1           1  2018-02-07 19:16:23   \n",
              "1     TCHWPBT   Male         1           1  2018-02-07 19:16:23   \n",
              "2     TCHWPBT   Male         1           1  2018-02-07 19:16:23   \n",
              "3     TCHWPBT   Male         1           1  2018-02-07 19:16:23   \n",
              "4     TCHWPBT   Male         1           1  2018-02-07 19:16:23   \n",
              "\n",
              "          updated_at_x  location_number location_type  latitude_x  \\\n",
              "0  2018-02-07 19:16:23                0          Work      -96.44   \n",
              "1  2018-02-07 19:16:23                0          Work      -96.44   \n",
              "2  2018-02-07 19:16:23                0          Work      -96.44   \n",
              "3  2018-02-07 19:16:23                0          Work      -96.44   \n",
              "4  2018-02-07 19:16:23                0          Work      -96.44   \n",
              "\n",
              "   longitude_x  ...  country_id  city_id         created_at_y  \\\n",
              "0        -67.2  ...         1.0      1.0  2018-01-30 14:42:04   \n",
              "1        -67.2  ...         1.0      1.0  2018-05-03 12:32:06   \n",
              "2        -67.2  ...         1.0      1.0  2018-05-04 22:28:22   \n",
              "3        -67.2  ...         1.0      1.0  2018-05-06 19:20:48   \n",
              "4        -67.2  ...         1.0      1.0  2018-05-17 22:12:38   \n",
              "\n",
              "          updated_at_y device_type  display_orders  location_number_obj  \\\n",
              "0  2020-04-07 15:12:43           3               1                    0   \n",
              "1  2020-04-05 20:46:03           3               1                    0   \n",
              "2  2020-04-07 16:35:55           3               1                    0   \n",
              "3  2020-04-02 00:56:17           3               1                    0   \n",
              "4  2020-04-05 15:57:41           3               1                    0   \n",
              "\n",
              "   id_obj  CID X LOC_NUM X VENDOR target  \n",
              "0       4         TCHWPBT X 0 X 4      0  \n",
              "1      13        TCHWPBT X 0 X 13      0  \n",
              "2      20        TCHWPBT X 0 X 20      0  \n",
              "3      23        TCHWPBT X 0 X 23      0  \n",
              "4      28        TCHWPBT X 0 X 28      0  \n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_full.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7de124",
      "metadata": {
        "id": "0b7de124",
        "outputId": "ababa75b-7186-43aa-ea96-d0090b55492f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>status_x</th>\n",
              "      <th>verified_x</th>\n",
              "      <th>created_at_x</th>\n",
              "      <th>updated_at_x</th>\n",
              "      <th>location_number</th>\n",
              "      <th>location_type</th>\n",
              "      <th>latitude_x</th>\n",
              "      <th>longitude_x</th>\n",
              "      <th>...</th>\n",
              "      <th>one_click_vendor</th>\n",
              "      <th>country_id</th>\n",
              "      <th>city_id</th>\n",
              "      <th>created_at_y</th>\n",
              "      <th>updated_at_y</th>\n",
              "      <th>device_type</th>\n",
              "      <th>display_orders</th>\n",
              "      <th>location_number_obj</th>\n",
              "      <th>id_obj</th>\n",
              "      <th>CID X LOC_NUM X VENDOR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ICE2DJP</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-01-30 14:42:04</td>\n",
              "      <td>2020-04-07 15:12:43</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>ICE2DJP X 0 X 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ICE2DJP</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-03 12:32:06</td>\n",
              "      <td>2020-04-05 20:46:03</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>ICE2DJP X 0 X 13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ICE2DJP</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-04 22:28:22</td>\n",
              "      <td>2020-04-07 16:35:55</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>ICE2DJP X 0 X 20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ICE2DJP</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-06 19:20:48</td>\n",
              "      <td>2020-04-02 00:56:17</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>ICE2DJP X 0 X 23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ICE2DJP</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>2018-02-07 16:45:36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-96.44</td>\n",
              "      <td>-67.2</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-05-17 22:12:38</td>\n",
              "      <td>2020-04-05 15:57:41</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>ICE2DJP X 0 X 28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 72 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  customer_id gender  status_x  verified_x         created_at_x  \\\n",
              "0     ICE2DJP   Male       1.0         1.0  2018-02-07 16:45:36   \n",
              "1     ICE2DJP   Male       1.0         1.0  2018-02-07 16:45:36   \n",
              "2     ICE2DJP   Male       1.0         1.0  2018-02-07 16:45:36   \n",
              "3     ICE2DJP   Male       1.0         1.0  2018-02-07 16:45:36   \n",
              "4     ICE2DJP   Male       1.0         1.0  2018-02-07 16:45:36   \n",
              "\n",
              "          updated_at_x  location_number location_type  latitude_x  \\\n",
              "0  2018-02-07 16:45:36              0.0           NaN      -96.44   \n",
              "1  2018-02-07 16:45:36              0.0           NaN      -96.44   \n",
              "2  2018-02-07 16:45:36              0.0           NaN      -96.44   \n",
              "3  2018-02-07 16:45:36              0.0           NaN      -96.44   \n",
              "4  2018-02-07 16:45:36              0.0           NaN      -96.44   \n",
              "\n",
              "   longitude_x  ...  one_click_vendor  country_id  city_id  \\\n",
              "0        -67.2  ...                 Y         1.0      1.0   \n",
              "1        -67.2  ...                 Y         1.0      1.0   \n",
              "2        -67.2  ...                 Y         1.0      1.0   \n",
              "3        -67.2  ...                 Y         1.0      1.0   \n",
              "4        -67.2  ...                 Y         1.0      1.0   \n",
              "\n",
              "          created_at_y         updated_at_y  device_type  display_orders  \\\n",
              "0  2018-01-30 14:42:04  2020-04-07 15:12:43          3.0             1.0   \n",
              "1  2018-05-03 12:32:06  2020-04-05 20:46:03          3.0             1.0   \n",
              "2  2018-05-04 22:28:22  2020-04-07 16:35:55          3.0             1.0   \n",
              "3  2018-05-06 19:20:48  2020-04-02 00:56:17          3.0             1.0   \n",
              "4  2018-05-17 22:12:38  2020-04-05 15:57:41          3.0             1.0   \n",
              "\n",
              "   location_number_obj  id_obj CID X LOC_NUM X VENDOR  \n",
              "0                  0.0     4.0        ICE2DJP X 0 X 4  \n",
              "1                  0.0    13.0       ICE2DJP X 0 X 13  \n",
              "2                  0.0    20.0       ICE2DJP X 0 X 20  \n",
              "3                  0.0    23.0       ICE2DJP X 0 X 23  \n",
              "4                  0.0    28.0       ICE2DJP X 0 X 28  \n",
              "\n",
              "[5 rows x 72 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_full.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83152f7a",
      "metadata": {
        "id": "83152f7a"
      },
      "outputs": [],
      "source": [
        "#Sampling\n",
        "\n",
        "# Define a comprehensive set of stratifying variables\n",
        "stratifying_vars = ['gender', 'language', 'customer_location_type', 'restaurant_location_type', 'favorite_cuisine_type']\n",
        "\n",
        "# Function to perform stratified sampling\n",
        "def stratified_sample(df, stratify_cols, frac=0.25):\n",
        "    # Ensure all stratifying columns are present in the dataframe\n",
        "    stratify_cols = [col for col in stratify_cols if col in df.columns]\n",
        "    return df.groupby(stratify_cols, group_keys=False).apply(lambda x: x.sample(frac=frac))\n",
        "\n",
        "# Applying stratified sampling on train and test datasets\n",
        "train_sampled = stratified_sample(train_full, stratifying_vars, frac=0.25)\n",
        "test_sampled = stratified_sample(test_full, stratifying_vars, frac=0.25)\n",
        "\n",
        "# Saving the sampled data\n",
        "train_sampled.to_csv(\"C:/Users/Joash/Desktop/recommender/train_sampled.csv\", index=False)\n",
        "test_sampled.to_csv(\"C:/Users/Joash/Desktop/recommender/test_sampled.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aea88b7",
      "metadata": {
        "id": "9aea88b7",
        "outputId": "7e0e5f9a-7a0f-43dd-c1d4-b92cb4c6a4d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['customer_id', 'gender', 'status_x', 'verified_x', 'created_at_x', 'updated_at_x', 'location_number', 'location_type', 'latitude_x', 'longitude_x', 'id', 'authentication_id', 'latitude_y', 'longitude_y', 'vendor_category_en', 'vendor_category_id', 'delivery_charge', 'serving_distance', 'is_open', 'OpeningTime', 'OpeningTime2', 'prepration_time', 'commission', 'is_akeed_delivering', 'discount_percentage', 'status_y', 'verified_y', 'rank', 'language', 'vendor_rating', 'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2', 'primary_tags', 'open_close_flags', 'vendor_tag', 'vendor_tag_name', 'one_click_vendor', 'country_id', 'city_id', 'created_at_y', 'updated_at_y', 'device_type', 'display_orders', 'location_number_obj', 'id_obj', 'CID X LOC_NUM X VENDOR', 'target']\n"
          ]
        }
      ],
      "source": [
        "# Print column names of the train dataset\n",
        "print(train_sampled.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "646a7897",
      "metadata": {
        "id": "646a7897",
        "outputId": "f50d1f8b-d11e-49cf-d0b5-12f271e803c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['customer_id', 'gender', 'status_x', 'verified_x', 'created_at_x', 'updated_at_x', 'location_number', 'location_type', 'latitude_x', 'longitude_x', 'id', 'authentication_id', 'latitude_y', 'longitude_y', 'vendor_category_en', 'vendor_category_id', 'delivery_charge', 'serving_distance', 'is_open', 'OpeningTime', 'OpeningTime2', 'prepration_time', 'commission', 'is_akeed_delivering', 'discount_percentage', 'status_y', 'verified_y', 'rank', 'language', 'vendor_rating', 'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2', 'primary_tags', 'open_close_flags', 'vendor_tag', 'vendor_tag_name', 'one_click_vendor', 'country_id', 'city_id', 'created_at_y', 'updated_at_y', 'device_type', 'display_orders', 'location_number_obj', 'id_obj', 'CID X LOC_NUM X VENDOR']\n"
          ]
        }
      ],
      "source": [
        "# Print column names of the test dataset\n",
        "print(test_sampled.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e05a3ad",
      "metadata": {
        "id": "6e05a3ad"
      },
      "outputs": [],
      "source": [
        "#Feature reduction\n",
        "# Updated columns to keep for the training dataset\n",
        "train_columns_to_keep = [\n",
        "    'customer_id', 'gender', 'language',\n",
        "    'location_number', 'location_type', 'latitude_x', 'longitude_x',\n",
        "    'id', 'latitude_y', 'longitude_y', 'vendor_category_en', 'vendor_rating',\n",
        "    'delivery_charge', 'serving_distance', 'is_open', 'discount_percentage',\n",
        "    'display_orders',\n",
        "    'vendor_tag_name','sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2',\n",
        "    'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2',\n",
        "    'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2',\n",
        "    'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2',\n",
        "    'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2',\n",
        "    'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2',\n",
        "    'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2',\n",
        "    'saturday_to_time2',\n",
        "    'target'  # 'target' column is specific to the training dataset\n",
        "]\n",
        "\n",
        "# Updated columns to keep for the testing dataset\n",
        "test_columns_to_keep = [\n",
        "    'customer_id', 'gender', 'language',\n",
        "    'location_number', 'location_type', 'latitude_x', 'longitude_x',\n",
        "    'id', 'latitude_y', 'longitude_y', 'vendor_category_en', 'vendor_rating',\n",
        "    'delivery_charge', 'serving_distance', 'is_open', 'discount_percentage',\n",
        "    'display_orders',  # Including 'display_orders'\n",
        "    'vendor_tag_name','sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2',\n",
        "    'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2',\n",
        "    'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2',\n",
        "    'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2',\n",
        "    'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2',\n",
        "    'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2',\n",
        "    'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2'\n",
        "]\n",
        "\n",
        "\n",
        "# Reduce features in the training dataset\n",
        "train_reduced = train_sampled[train_columns_to_keep]\n",
        "\n",
        "# Reduce features in the testing dataset\n",
        "test_reduced = test_sampled[test_columns_to_keep]\n",
        "\n",
        "# Save the reduced datasets\n",
        "train_reduced.to_csv(\"C:/Users/Joash/Desktop/recommender/train_reduced.csv\", index=False)\n",
        "test_reduced.to_csv(\"C:/Users/Joash/Desktop/recommender/test_reduced.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a2d3c9d",
      "metadata": {
        "id": "4a2d3c9d",
        "outputId": "16bce95d-c324-4689-ccaa-d9f5e923b5e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>language</th>\n",
              "      <th>location_number</th>\n",
              "      <th>location_type</th>\n",
              "      <th>latitude_x</th>\n",
              "      <th>longitude_x</th>\n",
              "      <th>id</th>\n",
              "      <th>latitude_y</th>\n",
              "      <th>longitude_y</th>\n",
              "      <th>...</th>\n",
              "      <th>thursday_to_time2</th>\n",
              "      <th>friday_from_time1</th>\n",
              "      <th>friday_to_time1</th>\n",
              "      <th>friday_from_time2</th>\n",
              "      <th>friday_to_time2</th>\n",
              "      <th>saturday_from_time1</th>\n",
              "      <th>saturday_to_time1</th>\n",
              "      <th>saturday_from_time2</th>\n",
              "      <th>saturday_to_time2</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4320162</th>\n",
              "      <td>M758NNC</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>1</td>\n",
              "      <td>Home</td>\n",
              "      <td>1.0990</td>\n",
              "      <td>0.6740</td>\n",
              "      <td>274</td>\n",
              "      <td>0.30540</td>\n",
              "      <td>0.5600</td>\n",
              "      <td>...</td>\n",
              "      <td>23:00:00</td>\n",
              "      <td>08:00:00</td>\n",
              "      <td>11:00:00</td>\n",
              "      <td>15:00:00</td>\n",
              "      <td>23:00:00</td>\n",
              "      <td>09:00:00</td>\n",
              "      <td>23:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242753</th>\n",
              "      <td>2DRL5BC</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.1268</td>\n",
              "      <td>-78.5600</td>\n",
              "      <td>221</td>\n",
              "      <td>0.02582</td>\n",
              "      <td>0.5520</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>09:00:00</td>\n",
              "      <td>23:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>09:00:00</td>\n",
              "      <td>23:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5310207</th>\n",
              "      <td>RHBGFFN</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>0</td>\n",
              "      <td>Other</td>\n",
              "      <td>0.1943</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>44</td>\n",
              "      <td>-0.93650</td>\n",
              "      <td>0.0819</td>\n",
              "      <td>...</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>00:01:00</td>\n",
              "      <td>01:30:00</td>\n",
              "      <td>17:45:00</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>00:01:00</td>\n",
              "      <td>01:30:00</td>\n",
              "      <td>17:45:00</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600084</th>\n",
              "      <td>CSK98OV</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.9380</td>\n",
              "      <td>-0.1848</td>\n",
              "      <td>577</td>\n",
              "      <td>-0.75500</td>\n",
              "      <td>0.2197</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12:00:00</td>\n",
              "      <td>22:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12:00:00</td>\n",
              "      <td>22:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5064804</th>\n",
              "      <td>15QGTMC</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.6250</td>\n",
              "      <td>-1.4740</td>\n",
              "      <td>28</td>\n",
              "      <td>0.48070</td>\n",
              "      <td>0.5527</td>\n",
              "      <td>...</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>00:01:00</td>\n",
              "      <td>01:30:00</td>\n",
              "      <td>17:45:00</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>00:01:00</td>\n",
              "      <td>01:30:00</td>\n",
              "      <td>17:45:00</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        customer_id  gender language  location_number location_type  \\\n",
              "4320162     M758NNC  Female       EN                1          Home   \n",
              "1242753     2DRL5BC  Female       EN                0           NaN   \n",
              "5310207     RHBGFFN  Female       EN                0         Other   \n",
              "600084      CSK98OV  Female       EN                3           NaN   \n",
              "5064804     15QGTMC  Female       EN                0           NaN   \n",
              "\n",
              "         latitude_x  longitude_x   id  latitude_y  longitude_y  ...  \\\n",
              "4320162      1.0990       0.6740  274     0.30540       0.5600  ...   \n",
              "1242753     -0.1268     -78.5600  221     0.02582       0.5520  ...   \n",
              "5310207      0.1943       0.3857   44    -0.93650       0.0819  ...   \n",
              "600084      -0.9380      -0.1848  577    -0.75500       0.2197  ...   \n",
              "5064804     12.6250      -1.4740   28     0.48070       0.5527  ...   \n",
              "\n",
              "        thursday_to_time2  friday_from_time1  friday_to_time1  \\\n",
              "4320162          23:00:00           08:00:00         11:00:00   \n",
              "1242753               NaN           09:00:00         23:00:00   \n",
              "5310207          23:59:00           00:01:00         01:30:00   \n",
              "600084                NaN           12:00:00         22:00:00   \n",
              "5064804          23:59:00           00:01:00         01:30:00   \n",
              "\n",
              "         friday_from_time2  friday_to_time2  saturday_from_time1  \\\n",
              "4320162           15:00:00         23:00:00             09:00:00   \n",
              "1242753                NaN              NaN             09:00:00   \n",
              "5310207           17:45:00         23:59:00             00:01:00   \n",
              "600084                 NaN              NaN             12:00:00   \n",
              "5064804           17:45:00         23:59:00             00:01:00   \n",
              "\n",
              "         saturday_to_time1 saturday_from_time2 saturday_to_time2 target  \n",
              "4320162           23:00:00                 NaN               NaN      0  \n",
              "1242753           23:00:00                 NaN               NaN      0  \n",
              "5310207           01:30:00            17:45:00          23:59:00      0  \n",
              "600084            22:00:00                 NaN               NaN      0  \n",
              "5064804           01:30:00            17:45:00          23:59:00      0  \n",
              "\n",
              "[5 rows x 47 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_reduced.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c73c234f",
      "metadata": {
        "id": "c73c234f",
        "outputId": "7b232577-bab7-41ce-c353-f6c2dc8e1cbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>language</th>\n",
              "      <th>location_number</th>\n",
              "      <th>location_type</th>\n",
              "      <th>latitude_x</th>\n",
              "      <th>longitude_x</th>\n",
              "      <th>id</th>\n",
              "      <th>latitude_y</th>\n",
              "      <th>longitude_y</th>\n",
              "      <th>...</th>\n",
              "      <th>thursday_from_time2</th>\n",
              "      <th>thursday_to_time2</th>\n",
              "      <th>friday_from_time1</th>\n",
              "      <th>friday_to_time1</th>\n",
              "      <th>friday_from_time2</th>\n",
              "      <th>friday_to_time2</th>\n",
              "      <th>saturday_from_time1</th>\n",
              "      <th>saturday_to_time1</th>\n",
              "      <th>saturday_from_time2</th>\n",
              "      <th>saturday_to_time2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>764572</th>\n",
              "      <td>NKXJQCZ</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Work</td>\n",
              "      <td>0.47680</td>\n",
              "      <td>-78.600000</td>\n",
              "      <td>310.0</td>\n",
              "      <td>-0.01683</td>\n",
              "      <td>0.514600</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10:00:00</td>\n",
              "      <td>16:40:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65717</th>\n",
              "      <td>Z068MF4</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.17270</td>\n",
              "      <td>0.605000</td>\n",
              "      <td>83.0</td>\n",
              "      <td>-0.92770</td>\n",
              "      <td>0.145900</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11:00:00</td>\n",
              "      <td>23:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11:00:00</td>\n",
              "      <td>23:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279146</th>\n",
              "      <td>M7GJ6TB</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Work</td>\n",
              "      <td>-0.02344</td>\n",
              "      <td>0.022250</td>\n",
              "      <td>196.0</td>\n",
              "      <td>-1.78700</td>\n",
              "      <td>0.006935</td>\n",
              "      <td>...</td>\n",
              "      <td>15:00:00</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>00:01:00</td>\n",
              "      <td>00:59:00</td>\n",
              "      <td>15:00:00</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>00:01:00</td>\n",
              "      <td>00:59:00</td>\n",
              "      <td>15:00:00</td>\n",
              "      <td>23:59:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>856580</th>\n",
              "      <td>4CGW6IQ</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Home</td>\n",
              "      <td>0.36380</td>\n",
              "      <td>-78.600000</td>\n",
              "      <td>537.0</td>\n",
              "      <td>-0.52400</td>\n",
              "      <td>0.052640</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>00:01:00</td>\n",
              "      <td>00:45:00</td>\n",
              "      <td>13:20:00</td>\n",
              "      <td>23:59:00</td>\n",
              "      <td>12:20:00</td>\n",
              "      <td>23:45:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1402171</th>\n",
              "      <td>9WDZ5QG</td>\n",
              "      <td>Female</td>\n",
              "      <td>EN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Home</td>\n",
              "      <td>0.44120</td>\n",
              "      <td>0.001471</td>\n",
              "      <td>304.0</td>\n",
              "      <td>-1.26800</td>\n",
              "      <td>0.028370</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10:00:00</td>\n",
              "      <td>23:15:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10:00:00</td>\n",
              "      <td>23:15:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        customer_id  gender language  location_number location_type  \\\n",
              "764572      NKXJQCZ  Female       EN              0.0          Work   \n",
              "65717       Z068MF4  Female       EN              0.0           NaN   \n",
              "279146      M7GJ6TB  Female       EN              2.0          Work   \n",
              "856580      4CGW6IQ  Female       EN              0.0          Home   \n",
              "1402171     9WDZ5QG  Female       EN              0.0          Home   \n",
              "\n",
              "         latitude_x  longitude_x     id  latitude_y  longitude_y  ...  \\\n",
              "764572      0.47680   -78.600000  310.0    -0.01683     0.514600  ...   \n",
              "65717       0.17270     0.605000   83.0    -0.92770     0.145900  ...   \n",
              "279146     -0.02344     0.022250  196.0    -1.78700     0.006935  ...   \n",
              "856580      0.36380   -78.600000  537.0    -0.52400     0.052640  ...   \n",
              "1402171     0.44120     0.001471  304.0    -1.26800     0.028370  ...   \n",
              "\n",
              "        thursday_from_time2  thursday_to_time2  friday_from_time1  \\\n",
              "764572                  NaN                NaN                NaN   \n",
              "65717                   NaN                NaN           11:00:00   \n",
              "279146             15:00:00           23:59:00           00:01:00   \n",
              "856580                  NaN                NaN           00:01:00   \n",
              "1402171                 NaN                NaN           10:00:00   \n",
              "\n",
              "         friday_to_time1  friday_from_time2  friday_to_time2  \\\n",
              "764572               NaN                NaN              NaN   \n",
              "65717           23:45:00                NaN              NaN   \n",
              "279146          00:59:00           15:00:00         23:59:00   \n",
              "856580          00:45:00           13:20:00         23:59:00   \n",
              "1402171         23:15:00                NaN              NaN   \n",
              "\n",
              "         saturday_from_time1 saturday_to_time1 saturday_from_time2  \\\n",
              "764572              10:00:00          16:40:00                 NaN   \n",
              "65717               11:00:00          23:45:00                 NaN   \n",
              "279146              00:01:00          00:59:00            15:00:00   \n",
              "856580              12:20:00          23:45:00                 NaN   \n",
              "1402171             10:00:00          23:15:00                 NaN   \n",
              "\n",
              "        saturday_to_time2  \n",
              "764572                NaN  \n",
              "65717                 NaN  \n",
              "279146           23:59:00  \n",
              "856580                NaN  \n",
              "1402171               NaN  \n",
              "\n",
              "[5 rows x 46 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_reduced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360ab9d2",
      "metadata": {
        "id": "360ab9d2",
        "outputId": "9801afe8-e6e3-488e-f1a1-9398a811cbb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "870676"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25bc5697",
      "metadata": {
        "id": "25bc5697",
        "outputId": "888eadee-c0a2-4127-c585-fba0c944310c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  vendor_category_en                                    vendor_tag_name  \\\n",
            "0     Sweets & Bakes                                       Cakes,Donuts   \n",
            "1     Sweets & Bakes                Fresh Juices,Healthy Food,Smoothies   \n",
            "2        Restaurants                  American,Burgers,Fries,Sandwiches   \n",
            "3        Restaurants                Burgers,Desserts,Family Meal,Salads   \n",
            "4        Restaurants                                            Burgers   \n",
            "5        Restaurants                       Asian,Fresh Juices,Kids meal   \n",
            "6        Restaurants                  American,Burgers,Fries,Sandwiches   \n",
            "7        Restaurants  Arabic,Biryani,Chinese,Grills,Indian,Rice,Sala...   \n",
            "8     Sweets & Bakes                                                NaN   \n",
            "9        Restaurants              Asian,Desserts,Rice,Salads,Soups,Thai   \n",
            "\n",
            "   vendor_rating  \n",
            "0            3.7  \n",
            "1            4.2  \n",
            "2            4.3  \n",
            "3            4.5  \n",
            "4            4.4  \n",
            "5            4.6  \n",
            "6            4.3  \n",
            "7            4.1  \n",
            "8            4.4  \n",
            "9            4.6  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_reduced_cleaned.csv\")\n",
        "\n",
        "# Display a sample of the specific columns\n",
        "sample_data = train_data[['vendor_category_en', 'vendor_tag_name', 'vendor_rating']].head(10)\n",
        "print(sample_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c42db87",
      "metadata": {
        "id": "1c42db87",
        "outputId": "ec147e5d-0fc6-4bc1-ea3c-4ec1dc14cca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      missing_values  percent_missing\n",
            "customer_id                        0         0.000000\n",
            "gender                             0         0.000000\n",
            "language                           0         0.000000\n",
            "location_number                    0         0.000000\n",
            "location_type                 392836        45.118506\n",
            "latitude_x                       118         0.013553\n",
            "longitude_x                      118         0.013553\n",
            "id                                 0         0.000000\n",
            "latitude_y                         0         0.000000\n",
            "longitude_y                        0         0.000000\n",
            "vendor_category_en                 0         0.000000\n",
            "vendor_rating                      0         0.000000\n",
            "delivery_charge                    0         0.000000\n",
            "serving_distance                   0         0.000000\n",
            "is_open                            0         0.000000\n",
            "discount_percentage                0         0.000000\n",
            "display_orders                     0         0.000000\n",
            "vendor_tag_name                30748         3.531509\n",
            "sunday_from_time1              10322         1.185516\n",
            "sunday_to_time1                10322         1.185516\n",
            "sunday_from_time2             563772        64.751067\n",
            "sunday_to_time2               563772        64.751067\n",
            "monday_from_time1                  0         0.000000\n",
            "monday_to_time1                    0         0.000000\n",
            "monday_from_time2             563772        64.751067\n",
            "monday_to_time2               563772        64.751067\n",
            "tuesday_from_time1             10322         1.185516\n",
            "tuesday_to_time1               10322         1.185516\n",
            "tuesday_from_time2            574003        65.926131\n",
            "tuesday_to_time2              574003        65.926131\n",
            "wednesday_from_time1               0         0.000000\n",
            "wednesday_to_time1                 0         0.000000\n",
            "wednesday_from_time2          563681        64.740615\n",
            "wednesday_to_time2            563681        64.740615\n",
            "thursday_from_time1            10322         1.185516\n",
            "thursday_to_time1              10322         1.185516\n",
            "thursday_from_time2           563772        64.751067\n",
            "thursday_to_time2             563772        64.751067\n",
            "friday_from_time1              31005         3.561026\n",
            "friday_to_time1                31005         3.561026\n",
            "friday_from_time2             532967        61.213011\n",
            "friday_to_time2               532967        61.213011\n",
            "saturday_from_time1            20701         2.377578\n",
            "saturday_to_time1              20701         2.377578\n",
            "saturday_from_time2           563733        64.746588\n",
            "saturday_to_time2             563733        64.746588\n",
            "target                             0         0.000000\n"
          ]
        }
      ],
      "source": [
        "# Analyzing missing values for train data\n",
        "missing_values = train_reduced.isnull().sum()\n",
        "percent_missing = (train_reduced.isnull().sum() / len(train_reduced)) * 100\n",
        "\n",
        "# Displaying the analysis\n",
        "missing_analysis = pd.DataFrame({'missing_values': missing_values, 'percent_missing': percent_missing})\n",
        "print(missing_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "630fb912",
      "metadata": {
        "id": "630fb912",
        "outputId": "7cb4a23c-e70f-43e2-e453-f315747fdb78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                      missing_values  percent_missing\n",
            "customer_id                        0         0.000000\n",
            "delivery_charge                    0         0.000000\n",
            "discount_percentage                0         0.000000\n",
            "display_orders                     0         0.000000\n",
            "friday_from_time1              31005         3.531046\n",
            "friday_from_time2             532967        61.180964\n",
            "friday_to_time1                31005         3.531046\n",
            "friday_to_time2               532967        61.180964\n",
            "gender                             0         0.000000\n",
            "id                                 0         0.000000\n",
            "is_open                            0         0.000000\n",
            "language                           0         0.000000\n",
            "latitude_x                       118         0.017157\n",
            "latitude_y                         0         0.000000\n",
            "location_number                    0         0.000000\n",
            "location_type                 392836        45.677696\n",
            "longitude_x                      118         0.017157\n",
            "longitude_y                        0         0.000000\n",
            "monday_from_time1                  0         0.000000\n",
            "monday_from_time2             563772        64.781454\n",
            "monday_to_time1                    0         0.000000\n",
            "monday_to_time2               563772        64.781454\n",
            "saturday_from_time1            20701         2.366830\n",
            "saturday_from_time2           563733        64.797794\n",
            "saturday_to_time1              20701         2.366830\n",
            "saturday_to_time2             563733        64.797794\n",
            "serving_distance                   0         0.000000\n",
            "sunday_from_time1              10322         1.194444\n",
            "sunday_from_time2             563772        64.781454\n",
            "sunday_to_time1                10322         1.194444\n",
            "sunday_to_time2               563772        64.781454\n",
            "target                             0              NaN\n",
            "thursday_from_time1            10322         1.194444\n",
            "thursday_from_time2           563772        64.781454\n",
            "thursday_to_time1              10322         1.194444\n",
            "thursday_to_time2             563772        64.781454\n",
            "tuesday_from_time1             10322         1.194444\n",
            "tuesday_from_time2            574003        66.003268\n",
            "tuesday_to_time1               10322         1.194444\n",
            "tuesday_to_time2              574003        66.003268\n",
            "vendor_category_en                 0         0.000000\n",
            "vendor_rating                      0         0.000000\n",
            "vendor_tag_name                30748         3.585784\n",
            "wednesday_from_time1               0         0.000000\n",
            "wednesday_from_time2          563681        64.808824\n",
            "wednesday_to_time1                 0         0.000000\n",
            "wednesday_to_time2            563681        64.808824\n"
          ]
        }
      ],
      "source": [
        "# Analyzing missing values for test data\n",
        "missing_values = train_reduced.isnull().sum()\n",
        "percent_missing = (test_reduced.isnull().sum() / len(test_reduced)) * 100\n",
        "\n",
        "# Displaying the analysis\n",
        "missing_analysis = pd.DataFrame({'missing_values': missing_values, 'percent_missing': percent_missing})\n",
        "print(missing_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff7bec7",
      "metadata": {
        "id": "0ff7bec7"
      },
      "outputs": [],
      "source": [
        "# Create independent copies to avoid SettingWithCopyWarning\n",
        "train_reduced = train_reduced.copy()\n",
        "test_reduced = test_reduced.copy()\n",
        "\n",
        "# Handling missing values in 'location_type'\n",
        "train_reduced['location_type'].fillna('Unknown', inplace=True)\n",
        "test_reduced['location_type'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Handling missing values in 'latitude_x' and 'longitude_x'\n",
        "train_reduced = train_reduced.dropna(subset=['latitude_x', 'longitude_x'])\n",
        "test_reduced = test_reduced.dropna(subset=['latitude_x', 'longitude_x'])\n",
        "\n",
        "# Save the datasets after handling missing values\n",
        "train_reduced.to_csv(\"C:/Users/Joash/Desktop/recommender/train_reduced_cleaned.csv\", index=False)\n",
        "test_reduced.to_csv(\"C:/Users/Joash/Desktop/recommender/test_reduced_cleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9414aab0",
      "metadata": {
        "id": "9414aab0",
        "outputId": "7cb1bf75-80e8-4a96-caf3-ec61982f8b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in training dataset:\n",
            " customer_id                  0\n",
            "gender                       0\n",
            "language                     0\n",
            "location_number              0\n",
            "location_type                0\n",
            "latitude_x                   0\n",
            "longitude_x                  0\n",
            "id                           0\n",
            "latitude_y                   0\n",
            "longitude_y                  0\n",
            "vendor_category_en           0\n",
            "vendor_rating                0\n",
            "delivery_charge              0\n",
            "serving_distance             0\n",
            "is_open                      0\n",
            "discount_percentage          0\n",
            "display_orders               0\n",
            "vendor_tag_name          30745\n",
            "sunday_from_time1        10322\n",
            "sunday_to_time1          10322\n",
            "sunday_from_time2       563695\n",
            "sunday_to_time2         563695\n",
            "monday_from_time1            0\n",
            "monday_to_time1              0\n",
            "monday_from_time2       563695\n",
            "monday_to_time2         563695\n",
            "tuesday_from_time1       10322\n",
            "tuesday_to_time1         10322\n",
            "tuesday_from_time2      573925\n",
            "tuesday_to_time2        573925\n",
            "wednesday_from_time1         0\n",
            "wednesday_to_time1           0\n",
            "wednesday_from_time2    563603\n",
            "wednesday_to_time2      563603\n",
            "thursday_from_time1      10322\n",
            "thursday_to_time1        10322\n",
            "thursday_from_time2     563695\n",
            "thursday_to_time2       563695\n",
            "friday_from_time1        31004\n",
            "friday_to_time1          31004\n",
            "friday_from_time2       532897\n",
            "friday_to_time2         532897\n",
            "saturday_from_time1      20701\n",
            "saturday_to_time1        20701\n",
            "saturday_from_time2     563657\n",
            "saturday_to_time2       563657\n",
            "target                       0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in testing dataset:\n",
            " customer_id                  0\n",
            "gender                       0\n",
            "language                     0\n",
            "location_number              0\n",
            "location_type                0\n",
            "latitude_x                   0\n",
            "longitude_x                  0\n",
            "id                           0\n",
            "latitude_y                   0\n",
            "longitude_y                  0\n",
            "vendor_category_en           0\n",
            "vendor_rating                0\n",
            "delivery_charge              0\n",
            "serving_distance             0\n",
            "is_open                      0\n",
            "discount_percentage          0\n",
            "display_orders               0\n",
            "vendor_tag_name           8777\n",
            "sunday_from_time1         2924\n",
            "sunday_to_time1           2924\n",
            "sunday_from_time2       158560\n",
            "sunday_to_time2         158560\n",
            "monday_from_time1            0\n",
            "monday_to_time1              0\n",
            "monday_from_time2       158560\n",
            "monday_to_time2         158560\n",
            "tuesday_from_time1        2924\n",
            "tuesday_to_time1          2924\n",
            "tuesday_from_time2      161550\n",
            "tuesday_to_time2        161550\n",
            "wednesday_from_time1         0\n",
            "wednesday_to_time1           0\n",
            "wednesday_from_time2    158626\n",
            "wednesday_to_time2      158626\n",
            "thursday_from_time1       2924\n",
            "thursday_to_time1         2924\n",
            "thursday_from_time2     158560\n",
            "thursday_to_time2       158560\n",
            "friday_from_time1         8644\n",
            "friday_to_time1           8644\n",
            "friday_from_time2       149748\n",
            "friday_to_time2         149748\n",
            "saturday_from_time1       5794\n",
            "saturday_to_time1         5794\n",
            "saturday_from_time2     158599\n",
            "saturday_to_time2       158599\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load the cleaned datasets\n",
        "train_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_reduced_cleaned.csv\")\n",
        "test_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_reduced_cleaned.csv\")\n",
        "\n",
        "# Check for missing values in the training dataset\n",
        "missing_values_train = train_reduced_cleaned.isnull().sum()\n",
        "print(\"Missing values in training dataset:\\n\", missing_values_train)\n",
        "\n",
        "# Check for missing values in the testing dataset\n",
        "missing_values_test = test_reduced_cleaned.isnull().sum()\n",
        "print(\"\\nMissing values in testing dataset:\\n\", missing_values_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c01bdf",
      "metadata": {
        "id": "e3c01bdf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Haversine formula to calculate distance between two lat-lon points\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371  # Earth radius in kilometers\n",
        "    dLat = np.radians(lat2 - lat1)\n",
        "    dLon = np.radians(lon2 - lon1)\n",
        "    a = np.sin(dLat/2) * np.sin(dLat/2) + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dLon/2) * np.sin(dLon/2)\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "    distance = R * c\n",
        "    return distance\n",
        "\n",
        "# Load the datasets\n",
        "train_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_reduced_cleaned.csv\")\n",
        "test_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_reduced_cleaned.csv\")\n",
        "\n",
        "# Apply the function to calculate distance\n",
        "train_reduced_cleaned['distance_customer_to_restaurant'] = train_reduced_cleaned.apply(lambda row: haversine(row['latitude_x'], row['longitude_x'], row['latitude_y'], row['longitude_y']), axis=1)\n",
        "test_reduced_cleaned['distance_customer_to_restaurant'] = test_reduced_cleaned.apply(lambda row: haversine(row['latitude_x'], row['longitude_x'], row['latitude_y'], row['longitude_y']), axis=1)\n",
        "\n",
        "# Save the datasets with the new feature\n",
        "train_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/train_feature_engineered.csv\", index=False)\n",
        "test_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/test_feature_engineered.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a4adf17",
      "metadata": {
        "id": "3a4adf17"
      },
      "outputs": [],
      "source": [
        "# Function to vectorize open hours calculation\n",
        "def vectorized_open_hours(from_time1, to_time1, from_time2, to_time2):\n",
        "    from_time1 = pd.to_datetime(from_time1, errors='coerce')\n",
        "    to_time1 = pd.to_datetime(to_time1, errors='coerce')\n",
        "    from_time2 = pd.to_datetime(from_time2, errors='coerce')\n",
        "    to_time2 = pd.to_datetime(to_time2, errors='coerce')\n",
        "\n",
        "    duration1 = np.where(pd.notna(from_time1) & pd.notna(to_time1), (to_time1 - from_time1).dt.total_seconds() / 3600, 0)\n",
        "    duration2 = np.where(pd.notna(from_time2) & pd.notna(to_time2), (to_time2 - from_time2).dt.total_seconds() / 3600, 0)\n",
        "\n",
        "    return duration1 + duration2\n",
        "\n",
        "# Load the datasets\n",
        "train_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_feature_engineered.csv\")\n",
        "test_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_feature_engineered.csv\")\n",
        "\n",
        "# List of days\n",
        "days = ['sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday']\n",
        "\n",
        "# Apply vectorized function for each day\n",
        "for day in days:\n",
        "    from_time1_col = f'{day}_from_time1'\n",
        "    to_time1_col = f'{day}_to_time1'\n",
        "    from_time2_col = f'{day}_from_time2'\n",
        "    to_time2_col = f'{day}_to_time2'\n",
        "\n",
        "    train_reduced_cleaned[f'{day}_open_hours'] = vectorized_open_hours(\n",
        "        train_reduced_cleaned[from_time1_col],\n",
        "        train_reduced_cleaned[to_time1_col],\n",
        "        train_reduced_cleaned[from_time2_col],\n",
        "        train_reduced_cleaned[to_time2_col])\n",
        "\n",
        "    test_reduced_cleaned[f'{day}_open_hours'] = vectorized_open_hours(\n",
        "        test_reduced_cleaned[from_time1_col],\n",
        "        test_reduced_cleaned[to_time1_col],\n",
        "        test_reduced_cleaned[from_time2_col],\n",
        "        test_reduced_cleaned[to_time2_col])\n",
        "\n",
        "# Save the datasets with new features\n",
        "train_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/train_full_feature_engineered.csv\", index=False)\n",
        "test_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/test_full_feature_engineered.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2fdd891",
      "metadata": {
        "id": "e2fdd891"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "train_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_full_feature_engineered.csv\")\n",
        "test_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_full_feature_engineered.csv\")\n",
        "\n",
        "# Feature: Binary indicator if the customer has multiple orders\n",
        "train_reduced_cleaned['multiple_orders_history'] = (train_reduced_cleaned['display_orders'] > 1).astype(int)\n",
        "test_reduced_cleaned['multiple_orders_history'] = (test_reduced_cleaned['display_orders'] > 1).astype(int)\n",
        "\n",
        "# Save the datasets with the new feature\n",
        "train_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/train_customer_feature_engineered.csv\", index=False)\n",
        "test_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/test_customer_feature_engineered.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adbd0a7c",
      "metadata": {
        "id": "adbd0a7c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "train_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_customer_feature_engineered.csv\")\n",
        "test_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_customer_feature_engineered.csv\")\n",
        "\n",
        "# Assuming 'location_number' represents different locations for a customer\n",
        "# Feature: Indicating if the customer uses multiple locations (as a proxy for location density)\n",
        "train_reduced_cleaned['uses_multiple_locations'] = (train_reduced_cleaned['location_number'] > 1).astype(int)\n",
        "test_reduced_cleaned['uses_multiple_locations'] = (test_reduced_cleaned['location_number'] > 1).astype(int)\n",
        "\n",
        "# Save the datasets with the new feature\n",
        "train_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/train_location_density_feature_engineered.csv\", index=False)\n",
        "test_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/test_location_density_feature_engineered.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4946bade",
      "metadata": {
        "id": "4946bade"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "train_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_location_density_feature_engineered.csv\")\n",
        "test_reduced_cleaned = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_location_density_feature_engineered.csv\")\n",
        "\n",
        "# Function to calculate cuisine diversity score\n",
        "def calculate_cuisine_diversity(cuisine_list):\n",
        "    # Assuming the cuisine list is a string of comma-separated values\n",
        "    cuisines = cuisine_list.split(',') if pd.notna(cuisine_list) else []\n",
        "    return len(set(cuisines))  # Count of unique cuisines\n",
        "\n",
        "# Apply the function to calculate cuisine diversity\n",
        "train_reduced_cleaned['cuisine_diversity_score'] = train_reduced_cleaned['vendor_tag_name'].apply(calculate_cuisine_diversity)\n",
        "test_reduced_cleaned['cuisine_diversity_score'] = test_reduced_cleaned['vendor_tag_name'].apply(calculate_cuisine_diversity)\n",
        "\n",
        "# Save the datasets with new features\n",
        "train_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/train_cuisine_feature_engineered.csv\", index=False)\n",
        "test_reduced_cleaned.to_csv(\"C:/Users/Joash/Desktop/recommender/test_cuisine_feature_engineered.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f4aae42",
      "metadata": {
        "id": "6f4aae42",
        "outputId": "1f4aa6f3-5263-4d8d-ed9a-55222e20332f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  sunday_from_time1 sunday_to_time1 monday_from_time1 monday_to_time1\n",
            "0          08:00:00        13:30:00          08:00:00        13:30:00\n",
            "1          09:00:00        23:00:00          09:00:00        23:00:00\n",
            "2          00:01:00        00:30:00          00:01:00        00:30:00\n",
            "3          12:00:00        22:00:00          12:00:00        22:00:00\n",
            "4          00:01:00        00:30:00          00:01:00        00:30:00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_full_feature_engineered.csv\")\n",
        "\n",
        "# Select time-related columns for inspection\n",
        "time_columns = ['sunday_from_time1', 'sunday_to_time1', 'monday_from_time1', 'monday_to_time1',  # Add other time columns here\n",
        "                # ... continue with other days\n",
        "               ]\n",
        "\n",
        "# Display the first few rows of these columns\n",
        "print(train_data[time_columns].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b9d7d2",
      "metadata": {
        "id": "a1b9d7d2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to convert time string to minutes past midnight\n",
        "def time_to_minutes(time_str):\n",
        "    if pd.isna(time_str):\n",
        "        return None\n",
        "    h, m, s = map(int, time_str.split(':'))\n",
        "    return h * 60 + m\n",
        "\n",
        "# Load the dataset with all features\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_cuisine_feature_engineered.csv\")\n",
        "test_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_cuisine_feature_engineered.csv\")\n",
        "\n",
        "# Convert time columns to numerical format\n",
        "time_columns = [\n",
        "    'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2',\n",
        "    'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2',\n",
        "    'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2',\n",
        "    'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2',\n",
        "    'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2',\n",
        "    'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2',\n",
        "    'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2',\n",
        "    'saturday_to_time2',\n",
        "               ]\n",
        "for col in time_columns:\n",
        "    train_data[col] = train_data[col].apply(time_to_minutes)\n",
        "    test_data[col] = test_data[col].apply(time_to_minutes)\n",
        "\n",
        "# Update the list of numerical columns to include the time columns\n",
        "numerical_cols = ['latitude_x', 'longitude_x', 'latitude_y', 'longitude_y',\n",
        "                  'delivery_charge', 'serving_distance', 'vendor_rating',\n",
        "                  'distance_customer_to_restaurant', 'cuisine_diversity_score'] + time_columns\n",
        "\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler()\n",
        "train_data[numerical_cols] = scaler.fit_transform(train_data[numerical_cols])\n",
        "test_data[numerical_cols] = scaler.transform(test_data[numerical_cols])\n",
        "\n",
        "# Save the fully preprocessed datasets\n",
        "train_data.to_csv(\"C:/Users/Joash/Desktop/recommender/train_preprocessed.csv\", index=False)\n",
        "test_data.to_csv(\"C:/Users/Joash/Desktop/recommender/test_preprocessed.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca4a5b0",
      "metadata": {
        "id": "cca4a5b0",
        "outputId": "44f0f509-252f-49eb-f55a-47ad659130cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in 'is_open': [0. 1.]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_preprocessed.csv\")\n",
        "\n",
        "# Check unique values in 'is_open'\n",
        "unique_values = train_data['is_open'].unique()\n",
        "print(\"Unique values in 'is_open':\", unique_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f8a04b",
      "metadata": {
        "id": "23f8a04b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the preprocessed datasets\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_preprocessed.csv\")\n",
        "test_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_preprocessed.csv\")\n",
        "\n",
        "# List of categorical columns to be encoded\n",
        "categorical_cols = ['gender', 'language', 'location_type',\n",
        "                    'vendor_category_en', 'vendor_tag_name']\n",
        "\n",
        "# Apply one-hot encoding\n",
        "train_data = pd.get_dummies(train_data, columns=categorical_cols, drop_first=True)\n",
        "test_data = pd.get_dummies(test_data, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Ensure the same set of columns in both datasets\n",
        "train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# Save the datasets after encoding\n",
        "train_data.to_csv(\"C:/Users/Joash/Desktop/recommender/train_encoded.csv\", index=False)\n",
        "test_data.to_csv(\"C:/Users/Joash/Desktop/recommender/test_encoded.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e845fdd3",
      "metadata": {
        "id": "e845fdd3",
        "outputId": "6dc78c03-3b48-41bf-c8c4-cc49d59a0869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skewness for delivery_charge: -0.46009618678622605\n",
            "Skewness for serving_distance: -0.828372649712824\n",
            "Skewness for vendor_rating: -1.3934843689537\n",
            "Skewness for sunday_from_time1: -0.5731249482278256\n",
            "Skewness for sunday_to_time1: -0.7714457536347894\n",
            "Skewness for sunday_from_time2: -0.15466781306976773\n",
            "Skewness for sunday_to_time2: -5.089450543281502\n",
            "Skewness for monday_from_time1: -0.5870268024683449\n",
            "Skewness for monday_to_time1: -0.7891607402589258\n",
            "Skewness for monday_from_time2: -0.15466781306976773\n",
            "Skewness for monday_to_time2: -5.089450543281502\n",
            "Skewness for tuesday_from_time1: -0.5846200382748934\n",
            "Skewness for tuesday_to_time1: -0.794839677702589\n",
            "Skewness for tuesday_from_time2: -0.09525063519672847\n",
            "Skewness for tuesday_to_time2: -5.005398175305493\n",
            "Skewness for wednesday_from_time1: -0.6024281859308628\n",
            "Skewness for wednesday_to_time1: -0.7765588315231134\n",
            "Skewness for wednesday_from_time2: -0.1373523212469297\n",
            "Skewness for wednesday_to_time2: -4.842083204137321\n",
            "Skewness for thursday_from_time1: -0.5649455819109395\n",
            "Skewness for thursday_to_time1: -0.7604054066240802\n",
            "Skewness for thursday_from_time2: -0.2065839216738387\n",
            "Skewness for thursday_to_time2: -4.840982786330054\n",
            "Skewness for friday_from_time1: -0.31293469492271253\n",
            "Skewness for friday_to_time1: -0.5910581328870874\n",
            "Skewness for friday_from_time2: -1.2791839194353851\n",
            "Skewness for friday_to_time2: -5.036168621696036\n",
            "Skewness for saturday_from_time1: -0.4951699055079598\n",
            "Skewness for saturday_to_time1: -0.8060908079829294\n",
            "Skewness for saturday_from_time2: -0.5266731850371844\n",
            "Skewness for saturday_to_time2: -2.6606902510766046\n",
            "Skewness for latitude_x: -5.310033748966145\n",
            "Skewness for longitude_x: -0.6490943951518825\n",
            "Skewness for latitude_y: 9.00520635863352\n",
            "Skewness for longitude_y: 8.967176858856808\n",
            "Skewness for distance_customer_to_restaurant: 0.6955936947157223\n",
            "Skewness for cuisine_diversity_score: 0.04603572666854268\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the encoded dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_encoded.csv\")\n",
        "\n",
        "# List of numerical columns to check for skewness\n",
        "numerical_cols = ['delivery_charge', 'serving_distance', 'vendor_rating',\n",
        "                  'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2',\n",
        "    'sunday_to_time2', 'monday_from_time1', 'monday_to_time1', 'monday_from_time2',\n",
        "    'monday_to_time2', 'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2',\n",
        "    'tuesday_to_time2', 'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2',\n",
        "    'wednesday_to_time2', 'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2',\n",
        "    'thursday_to_time2', 'friday_from_time1', 'friday_to_time1', 'friday_from_time2',\n",
        "    'friday_to_time2', 'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2',\n",
        "    'saturday_to_time2','latitude_x', 'longitude_x', 'latitude_y', 'longitude_y' ,\n",
        "                  'distance_customer_to_restaurant', 'cuisine_diversity_score',\n",
        "                 ]\n",
        "\n",
        "# Calculate and print skewness for each numerical column\n",
        "for col in numerical_cols:\n",
        "    skewness = train_data[col].skew()\n",
        "    print(f\"Skewness for {col}: {skewness}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34873c1a",
      "metadata": {
        "id": "34873c1a",
        "outputId": "d1b8b792-3330-49b4-b83d-e28335e28123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-positive values in latitude_x: 793853\n",
            "Non-positive values in latitude_y: 839768\n",
            "Non-positive values in longitude_y: 860236\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_encoded.csv\")\n",
        "\n",
        "# Check for non-positive values in skewed columns\n",
        "skewed_cols = ['latitude_x', 'latitude_y', 'longitude_y']\n",
        "for col in skewed_cols:\n",
        "    non_positive_count = train_data[train_data[col] <= 0][col].count()\n",
        "    print(f\"Non-positive values in {col}: {non_positive_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22be4596",
      "metadata": {
        "id": "22be4596"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_encoded.csv\")\n",
        "test_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/test_encoded.csv\")\n",
        "\n",
        "# Columns for Min-Max Normalization\n",
        "normalization_cols = ['latitude_x', 'latitude_y', 'longitude_y']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize specified columns\n",
        "train_data[normalization_cols] = scaler.fit_transform(train_data[normalization_cols])\n",
        "test_data[normalization_cols] = scaler.transform(test_data[normalization_cols])\n",
        "\n",
        "# Save the datasets after normalization\n",
        "train_data.to_csv(\"C:/Users/Joash/Desktop/recommender/train_normalized.csv\", index=False)\n",
        "test_data.to_csv(\"C:/Users/Joash/Desktop/recommender/test_normalized.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47e053e7",
      "metadata": {
        "id": "47e053e7",
        "outputId": "9206e8ca-5391-4c35-ca7b-9eeedf9e8546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (696446, 128)\n",
            "Validation set size: (174112, 128)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load the normalized training dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_normalized.csv\")\n",
        "\n",
        "# Separate features and target variable\n",
        "# Assuming 'target' is your label column. Adjust the column name if necessary\n",
        "X = train_data.drop('target', axis=1)  # Drop the target column to create feature set\n",
        "y = train_data['target']  # Target variable\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "# Here, 20% of the data is reserved for validation, and 80% for training\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optionally, you can check the size of each set\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Validation set size: {X_val.shape}\")\n",
        "\n",
        "# At this point, you can proceed to train your model using X_train and y_train\n",
        "# and validate it using X_val and y_val\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf405dc9",
      "metadata": {
        "id": "bf405dc9",
        "outputId": "d44732a7-6b08-4f4b-d25a-5cc9324d64ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scikit-surprise imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from surprise import SVD\n",
        "print(\"scikit-surprise imported successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b9b7aa",
      "metadata": {
        "id": "85b9b7aa",
        "outputId": "5dbfa4d9-a169-4422-b786-92229f95ada3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\joash\\anaconda3\\lib\\site-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\joash\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joash\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\joash\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\joash\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c7dffdc",
      "metadata": {
        "id": "4c7dffdc",
        "outputId": "28b76f36-78b1-4925-8a66-e6795aad832b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.1288  0.1263  0.1245  0.1237  0.1267  0.1260  0.0018  \n",
            "MAE (testset)     0.0329  0.0323  0.0318  0.0318  0.0324  0.0322  0.0004  \n",
            "Fit time          8.89    9.88    9.16    9.08    8.98    9.20    0.35    \n",
            "Test time         1.96    1.74    1.77    1.58    1.74    1.76    0.12    \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_rmse': array([0.12882   , 0.12628358, 0.12449655, 0.12372013, 0.12668769]),\n",
              " 'test_mae': array([0.0328817 , 0.03229126, 0.03177193, 0.03179656, 0.03242626]),\n",
              " 'fit_time': (8.88984227180481,\n",
              "  9.882625579833984,\n",
              "  9.159491062164307,\n",
              "  9.078585863113403,\n",
              "  8.984183073043823),\n",
              " 'test_time': (1.9616830348968506,\n",
              "  1.7426011562347412,\n",
              "  1.7713344097137451,\n",
              "  1.584249496459961,\n",
              "  1.7397818565368652)}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_normalized.csv\")\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Reshape the data for Surprise\n",
        "reader = Reader(rating_scale=(0, 1))  # Assuming ratings are binary (0 or 1)\n",
        "data = Dataset.load_from_df(train_data[['customer_id', 'id', 'target']], reader)\n",
        "\n",
        "# Define the SVD algorithm\n",
        "svd = SVD()\n",
        "\n",
        "# Perform cross-validation (you can later use train-test split or full train)\n",
        "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe985db1",
      "metadata": {
        "id": "fe985db1",
        "outputId": "bd9395b8-2cd9-4522-ffdc-7ac97d25c61d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# packages in environment at C:\\Users\\Joash\\anaconda3:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n"
          ]
        }
      ],
      "source": [
        "!conda list scikit-surprise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31204a20",
      "metadata": {
        "id": "31204a20",
        "outputId": "b539ab95-7549-4de1-fd41-84f362baae4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# packages in environment at C:\\Users\\Joash\\anaconda3:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "_anaconda_depends         2023.07                 py311_1  \n",
            "abseil-cpp                20211102.0           hd77b12b_0  \n",
            "aiobotocore               2.4.2           py311haa95532_0  \n",
            "aiofiles                  22.1.0          py311haa95532_0  \n",
            "aiohttp                   3.8.3           py311h2bbff1b_0  \n",
            "aioitertools              0.7.1              pyhd3eb1b0_0  \n",
            "aiosignal                 1.2.0              pyhd3eb1b0_0  \n",
            "aiosqlite                 0.18.0          py311haa95532_0  \n",
            "alabaster                 0.7.12             pyhd3eb1b0_0  \n",
            "anaconda-catalogs         0.2.0           py311haa95532_0  \n",
            "anaconda-client           1.12.0          py311haa95532_0  \n",
            "anaconda-navigator        2.4.2           py311haa95532_0  \n",
            "anaconda-project          0.11.1          py311haa95532_0  \n",
            "anyio                     3.5.0           py311haa95532_0  \n",
            "appdirs                   1.4.4              pyhd3eb1b0_0  \n",
            "argon2-cffi               21.3.0             pyhd3eb1b0_0  \n",
            "argon2-cffi-bindings      21.2.0          py311h2bbff1b_0  \n",
            "arrow                     1.2.3           py311haa95532_1  \n",
            "arrow-cpp                 11.0.0          py311h308b814_0  \n",
            "astroid                   2.14.2          py311haa95532_0  \n",
            "astropy                   5.1             py311h5bb9823_0  \n",
            "asttokens                 2.0.5              pyhd3eb1b0_0  \n",
            "async-timeout             4.0.2           py311haa95532_0  \n",
            "atomicwrites              1.4.0                      py_0  \n",
            "attrs                     22.1.0          py311haa95532_0  \n",
            "automat                   20.2.0                     py_0  \n",
            "autopep8                  1.6.0              pyhd3eb1b0_1  \n",
            "aws-c-common              0.4.57               ha925a31_1  \n",
            "aws-c-event-stream        0.1.6                hd77b12b_5  \n",
            "aws-checksums             0.1.9                ha925a31_0  \n",
            "aws-sdk-cpp               1.8.185              hd77b12b_0  \n",
            "babel                     2.11.0          py311haa95532_0  \n",
            "backcall                  0.2.0              pyhd3eb1b0_0  \n",
            "backports                 1.1                pyhd3eb1b0_0  \n",
            "backports.functools_lru_cache 1.6.4              pyhd3eb1b0_0  \n",
            "backports.tempfile        1.0                pyhd3eb1b0_1  \n",
            "backports.weakref         1.0.post1                  py_1  \n",
            "bcrypt                    3.2.0           py311h2bbff1b_1  \n",
            "beautifulsoup4            4.12.2          py311haa95532_0  \n",
            "binaryornot               0.4.4              pyhd3eb1b0_1  \n",
            "black                     23.3.0          py311haa95532_0  \n",
            "blas                      1.0                         mkl  \n",
            "bleach                    4.1.0              pyhd3eb1b0_0  \n",
            "blosc                     1.21.3               h6c2663c_0  \n",
            "bokeh                     3.2.1           py311h746a85d_0  \n",
            "boltons                   23.0.0          py311haa95532_0  \n",
            "boost-cpp                 1.73.0              h2bbff1b_12  \n",
            "boto3                     1.24.28         py311haa95532_0  \n",
            "botocore                  1.27.59         py311haa95532_0  \n",
            "bottleneck                1.3.5           py311h5bb9823_0  \n",
            "brotli                    1.0.9                h2bbff1b_7  \n",
            "brotli-bin                1.0.9                h2bbff1b_7  \n",
            "brotlipy                  0.7.0           py311h2bbff1b_1002  \n",
            "bzip2                     1.0.8                he774522_0  \n",
            "c-ares                    1.19.0               h2bbff1b_0  \n",
            "c-blosc2                  2.8.0                hd77b12b_0  \n",
            "ca-certificates           2023.05.30           haa95532_0  \n",
            "certifi                   2023.7.22       py311haa95532_0  \n",
            "cffi                      1.15.1          py311h2bbff1b_3  \n",
            "cfitsio                   3.470                h2bbff1b_7  \n",
            "chardet                   4.0.0           py311haa95532_1003  \n",
            "charls                    2.2.0                h6c2663c_0  \n",
            "charset-normalizer        2.0.4              pyhd3eb1b0_0  \n",
            "click                     8.0.4           py311haa95532_0  \n",
            "cloudpickle               2.2.1           py311haa95532_0  \n",
            "clyent                    1.2.2           py311haa95532_1  \n",
            "colorama                  0.4.6           py311haa95532_0  \n",
            "colorcet                  3.0.1           py311haa95532_0  \n",
            "comm                      0.1.2           py311haa95532_0  \n",
            "conda                     23.7.2          py311haa95532_0  \n",
            "conda-build               3.26.0          py311haa95532_0  \n",
            "conda-content-trust       0.1.1              pyhd3eb1b0_0  \n",
            "conda-index               0.2.3           py311haa95532_0  \n",
            "conda-libmamba-solver     23.5.0          py311haa95532_0  \n",
            "conda-pack                0.6.0              pyhd3eb1b0_0  \n",
            "conda-package-handling    2.2.0           py311haa95532_0  \n",
            "conda-package-streaming   0.9.0           py311haa95532_0  \n",
            "conda-repo-cli            1.0.41          py311haa95532_0  \n",
            "conda-token               0.4.0              pyhd3eb1b0_0  \n",
            "conda-verify              3.4.2                      py_1  \n",
            "console_shortcut          0.1.1                         4  \n",
            "constantly                15.1.0          py311haa95532_0  \n",
            "contourpy                 1.0.5           py311h59b6b97_0  \n",
            "cookiecutter              1.7.3              pyhd3eb1b0_0  \n",
            "cryptography              41.0.2          py311h31511bf_0  \n",
            "cssselect                 1.1.0              pyhd3eb1b0_0  \n",
            "curl                      8.1.1                he2ea4bf_2  \n",
            "cycler                    0.11.0             pyhd3eb1b0_0  \n",
            "cytoolz                   0.12.0          py311h2bbff1b_0  \n",
            "daal4py                   2023.1.1        py311h30df693_0  \n",
            "dal                       2023.1.1         h59b6b97_48681  \n",
            "dask                      2023.6.0        py311haa95532_0  \n",
            "dask-core                 2023.6.0        py311haa95532_0  \n",
            "datashader                0.15.1          py311haa95532_0  \n",
            "datashape                 0.5.4           py311haa95532_1  \n",
            "debugpy                   1.6.7           py311hd77b12b_0  \n",
            "decorator                 5.1.1              pyhd3eb1b0_0  \n",
            "defusedxml                0.7.1              pyhd3eb1b0_0  \n",
            "diff-match-patch          20200713           pyhd3eb1b0_0  \n",
            "dill                      0.3.6           py311haa95532_0  \n",
            "distributed               2023.6.0        py311haa95532_0  \n",
            "docstring-to-markdown     0.11            py311haa95532_0  \n",
            "docutils                  0.18.1          py311haa95532_3  \n",
            "entrypoints               0.4             py311haa95532_0  \n",
            "et_xmlfile                1.1.0           py311haa95532_0  \n",
            "executing                 0.8.3              pyhd3eb1b0_0  \n",
            "filelock                  3.9.0           py311haa95532_0  \n",
            "flake8                    6.0.0           py311haa95532_0  \n",
            "flask                     2.2.2           py311haa95532_0  \n",
            "fmt                       9.1.0                h6d14046_0  \n",
            "fonttools                 4.25.0             pyhd3eb1b0_0  \n",
            "freetype                  2.12.1               ha860e81_0  \n",
            "frozenlist                1.3.3           py311h2bbff1b_0  \n",
            "fsspec                    2023.3.0        py311haa95532_0  \n",
            "future                    0.18.3          py311haa95532_0  \n",
            "gensim                    4.3.0           py311heda8569_0  \n",
            "gflags                    2.2.2                ha925a31_0  \n",
            "giflib                    5.2.1                h8cc25b3_3  \n",
            "glib                      2.69.1               h5dc1a3c_2  \n",
            "glob2                     0.7                pyhd3eb1b0_0  \n",
            "glog                      0.5.0                hd77b12b_0  \n",
            "greenlet                  2.0.1           py311hd77b12b_0  \n",
            "gst-plugins-base          1.18.5               h9e645db_0  \n",
            "gstreamer                 1.18.5               hd78058f_0  \n",
            "h2o                       3.44.0.2                 pypi_0    pypi\n",
            "h5py                      3.7.0           py311h259cc0e_0  \n",
            "hdf5                      1.10.6               h1756f20_1  \n",
            "heapdict                  1.0.1              pyhd3eb1b0_0  \n",
            "holoviews                 1.17.0          py311haa95532_0  \n",
            "hvplot                    0.8.4           py311haa95532_0  \n",
            "hyperlink                 21.0.0             pyhd3eb1b0_0  \n",
            "icc_rt                    2022.1.0             h6049295_2  \n",
            "icu                       58.2                 ha925a31_3  \n",
            "idna                      3.4             py311haa95532_0  \n",
            "imagecodecs               2021.8.26       py311h94f204c_2  \n",
            "imageio                   2.26.0          py311haa95532_0  \n",
            "imagesize                 1.4.1           py311haa95532_0  \n",
            "imbalanced-learn          0.10.1          py311haa95532_1  \n",
            "importlib-metadata        6.0.0           py311haa95532_0  \n",
            "importlib_metadata        6.0.0                hd3eb1b0_0  \n",
            "incremental               21.3.0             pyhd3eb1b0_0  \n",
            "inflection                0.5.1           py311haa95532_0  \n",
            "iniconfig                 1.1.1              pyhd3eb1b0_0  \n",
            "intake                    0.6.8           py311haa95532_0  \n",
            "intel-openmp              2023.1.0         h59b6b97_46319  \n",
            "intervaltree              3.1.0              pyhd3eb1b0_0  \n",
            "ipykernel                 6.19.2          py311h86cfffd_0  \n",
            "ipython                   8.12.0          py311haa95532_0  \n",
            "ipython_genutils          0.2.0              pyhd3eb1b0_1  \n",
            "ipywidgets                8.0.4           py311haa95532_0  \n",
            "isort                     5.9.3              pyhd3eb1b0_0  \n",
            "itemadapter               0.3.0              pyhd3eb1b0_0  \n",
            "itemloaders               1.0.4              pyhd3eb1b0_1  \n",
            "itsdangerous              2.0.1              pyhd3eb1b0_0  \n",
            "jaraco.classes            3.2.1              pyhd3eb1b0_0  \n",
            "jedi                      0.18.1          py311haa95532_1  \n",
            "jellyfish                 0.9.0           py311h2bbff1b_0  \n",
            "jinja2                    3.1.2           py311haa95532_0  \n",
            "jinja2-time               0.2.0              pyhd3eb1b0_3  \n",
            "jmespath                  0.10.0             pyhd3eb1b0_0  \n",
            "joblib                    1.2.0           py311haa95532_0  \n",
            "jpeg                      9e                   h2bbff1b_1  \n",
            "jq                        1.6                  haa95532_1  \n",
            "json5                     0.9.6              pyhd3eb1b0_0  \n",
            "jsonpatch                 1.32               pyhd3eb1b0_0  \n",
            "jsonpointer               2.1                pyhd3eb1b0_0  \n",
            "jsonschema                4.17.3          py311haa95532_0  \n",
            "jupyter                   1.0.0           py311haa95532_8  \n",
            "jupyter_client            7.4.9           py311haa95532_0  \n",
            "jupyter_console           6.6.3           py311haa95532_0  \n",
            "jupyter_core              5.3.0           py311haa95532_0  \n",
            "jupyter_events            0.6.3           py311haa95532_0  \n",
            "jupyter_server            1.23.4          py311haa95532_0  \n",
            "jupyter_server_fileid     0.9.0           py311haa95532_0  \n",
            "jupyter_server_ydoc       0.8.0           py311haa95532_1  \n",
            "jupyter_ydoc              0.2.4           py311haa95532_0  \n",
            "jupyterlab                3.6.3           py311haa95532_0  \n",
            "jupyterlab_pygments       0.1.2                      py_0  \n",
            "jupyterlab_server         2.22.0          py311haa95532_0  \n",
            "jupyterlab_widgets        3.0.5           py311haa95532_0  \n",
            "jxrlib                    1.1                  he774522_2  \n",
            "keyring                   23.13.1         py311haa95532_0  \n",
            "kiwisolver                1.4.4           py311hd77b12b_0  \n",
            "krb5                      1.19.4               h5b6d351_0  \n",
            "lazy-object-proxy         1.6.0           py311h2bbff1b_0  \n",
            "lazy_loader               0.2             py311haa95532_0  \n",
            "lcms2                     2.12                 h83e58a3_0  \n",
            "lerc                      3.0                  hd77b12b_0  \n",
            "libaec                    1.0.4                h33f27b4_1  \n",
            "libarchive                3.6.2                h2033e3e_1  \n",
            "libboost                  1.73.0              h6c2663c_12  \n",
            "libbrotlicommon           1.0.9                h2bbff1b_7  \n",
            "libbrotlidec              1.0.9                h2bbff1b_7  \n",
            "libbrotlienc              1.0.9                h2bbff1b_7  \n",
            "libclang                  14.0.6          default_hb5a9fac_1  \n",
            "libclang13                14.0.6          default_h8e68704_1  \n",
            "libcurl                   8.1.1                h86230a5_2  \n",
            "libdeflate                1.17                 h2bbff1b_0  \n",
            "libevent                  2.1.12               hcc03200_0  \n",
            "libffi                    3.4.4                hd77b12b_0  \n",
            "libiconv                  1.16                 h2bbff1b_2  \n",
            "liblief                   0.12.3               hd77b12b_0  \n",
            "libllvm14                 14.0.6               h4157e71_3  \n",
            "libmamba                  1.4.1                h214f63a_0  \n",
            "libmambapy                1.4.1           py311h214f63a_0  \n",
            "libogg                    1.3.5                h2bbff1b_1  \n",
            "libpng                    1.6.39               h8cc25b3_0  \n",
            "libprotobuf               3.20.3               h23ce68f_0  \n",
            "libsodium                 1.0.18               h62dcd97_0  \n",
            "libsolv                   0.7.22               h23ce68f_0  \n",
            "libspatialindex           1.9.3                h6c2663c_0  \n",
            "libssh2                   1.10.0               hcd4344a_2  \n",
            "libthrift                 0.15.0               he49ee6e_2  \n",
            "libtiff                   4.5.0                h6c2663c_2  \n",
            "libvorbis                 1.3.7                he774522_0  \n",
            "libwebp                   1.2.4                hbc33d0d_1  \n",
            "libwebp-base              1.2.4                h2bbff1b_1  \n",
            "libxml2                   2.10.3               h0ad7f3c_0  \n",
            "libxslt                   1.1.37               h2bbff1b_0  \n",
            "libzopfli                 1.0.3                ha925a31_0  \n",
            "linkify-it-py             2.0.0           py311haa95532_0  \n",
            "llvmlite                  0.40.0          py311hf2fb9eb_0  \n",
            "locket                    1.0.0           py311haa95532_0  \n",
            "lxml                      4.9.2           py311h2bbff1b_0  \n",
            "lz4                       4.3.2           py311h2bbff1b_0  \n",
            "lz4-c                     1.9.4                h2bbff1b_0  \n",
            "lzo                       2.10                 he774522_2  \n",
            "m2-msys2-runtime          2.5.0.17080.65c939c               3  \n",
            "m2-patch                  2.7.5                         2  \n",
            "m2w64-libwinpthread-git   5.0.0.4634.697f757               2  \n",
            "markdown                  3.4.1           py311haa95532_0  \n",
            "markdown-it-py            2.2.0           py311haa95532_1  \n",
            "markupsafe                2.1.1           py311h2bbff1b_0  \n",
            "matplotlib                3.7.1           py311haa95532_1  \n",
            "matplotlib-base           3.7.1           py311hf62ec03_1  \n",
            "matplotlib-inline         0.1.6           py311haa95532_0  \n",
            "mccabe                    0.7.0              pyhd3eb1b0_0  \n",
            "mdit-py-plugins           0.3.0           py311haa95532_0  \n",
            "mdurl                     0.1.0           py311haa95532_0  \n",
            "menuinst                  1.4.19          py311h59b6b97_1  \n",
            "mistune                   0.8.4           py311h2bbff1b_1000  \n",
            "mkl                       2023.1.0         h8bd8f75_46356  \n",
            "mkl-service               2.4.0           py311h2bbff1b_1  \n",
            "mkl_fft                   1.3.6           py311hf62ec03_1  \n",
            "mkl_random                1.2.2           py311hf62ec03_1  \n",
            "more-itertools            8.12.0             pyhd3eb1b0_0  \n",
            "mpmath                    1.3.0           py311haa95532_0  \n",
            "msgpack-python            1.0.3           py311h59b6b97_0  \n",
            "msys2-conda-epoch         20160418                      1  \n",
            "multidict                 6.0.2           py311h2bbff1b_0  \n",
            "multipledispatch          0.6.0           py311haa95532_0  \n",
            "munkres                   1.1.4                      py_0  \n",
            "mypy_extensions           0.4.3           py311haa95532_1  \n",
            "navigator-updater         0.4.0           py311haa95532_0  \n",
            "nbclassic                 0.5.5           py311haa95532_0  \n",
            "nbclient                  0.5.13          py311haa95532_0  \n",
            "nbconvert                 6.5.4           py311haa95532_0  \n",
            "nbformat                  5.7.0           py311haa95532_0  \n",
            "nest-asyncio              1.5.6           py311haa95532_0  \n",
            "networkx                  3.1             py311haa95532_0  \n",
            "nltk                      3.8.1           py311haa95532_0  \n",
            "notebook                  6.5.4           py311haa95532_1  \n",
            "notebook-shim             0.2.2           py311haa95532_0  \n",
            "numba                     0.57.0          py311hf62ec03_0  \n",
            "numexpr                   2.8.4           py311h1fcbade_1  \n",
            "numpy                     1.24.3          py311hdab7c0b_1  \n",
            "numpy-base                1.24.3          py311hd01c5d8_1  \n",
            "numpydoc                  1.5.0           py311haa95532_0  \n",
            "openjpeg                  2.4.0                h4fc8c34_0  \n",
            "openpyxl                  3.0.10          py311h2bbff1b_0  \n",
            "openssl                   1.1.1u               h2bbff1b_0  \n",
            "orc                       1.7.4                h623e30f_1  \n",
            "packaging                 23.0            py311haa95532_0  \n",
            "pandas                    1.5.3           py311heda8569_0  \n",
            "pandocfilters             1.5.0              pyhd3eb1b0_0  \n",
            "panel                     1.2.1           py311haa95532_0  \n",
            "param                     1.13.0          py311haa95532_0  \n",
            "paramiko                  2.8.1              pyhd3eb1b0_0  \n",
            "parsel                    1.6.0           py311haa95532_0  \n",
            "parso                     0.8.3              pyhd3eb1b0_0  \n",
            "partd                     1.2.0              pyhd3eb1b0_1  \n",
            "pathlib                   1.0.1              pyhd3eb1b0_1  \n",
            "pathspec                  0.10.3          py311haa95532_0  \n",
            "patsy                     0.5.3           py311haa95532_0  \n",
            "pcre                      8.45                 hd77b12b_0  \n",
            "pcre2                     10.37                h0ff8eda_1  \n",
            "pep8                      1.7.1           py311haa95532_1  \n",
            "pexpect                   4.8.0              pyhd3eb1b0_3  \n",
            "pickleshare               0.7.5           pyhd3eb1b0_1003  \n",
            "pillow                    9.4.0           py311hd77b12b_0  \n",
            "pip                       23.2.1          py311haa95532_0  \n",
            "pkginfo                   1.9.6           py311haa95532_0  \n",
            "platformdirs              2.5.2           py311haa95532_0  \n",
            "plotly                    5.9.0           py311haa95532_0  \n",
            "pluggy                    1.0.0           py311haa95532_1  \n",
            "ply                       3.11            py311haa95532_0  \n",
            "pooch                     1.4.0              pyhd3eb1b0_0  \n",
            "powershell_shortcut       0.0.1                         3  \n",
            "poyo                      0.5.0              pyhd3eb1b0_0  \n",
            "prometheus_client         0.14.1          py311haa95532_0  \n",
            "prompt-toolkit            3.0.36          py311haa95532_0  \n",
            "prompt_toolkit            3.0.36               hd3eb1b0_0  \n",
            "protego                   0.1.16                     py_0  \n",
            "psutil                    5.9.0           py311h2bbff1b_0  \n",
            "ptyprocess                0.7.0              pyhd3eb1b0_2  \n",
            "pure_eval                 0.2.2              pyhd3eb1b0_0  \n",
            "py-cpuinfo                8.0.0              pyhd3eb1b0_1  \n",
            "py-lief                   0.12.3          py311hd77b12b_0  \n",
            "pyarrow                   11.0.0          py311h8a3a540_0  \n",
            "pyasn1                    0.4.8              pyhd3eb1b0_0  \n",
            "pyasn1-modules            0.2.8                      py_0  \n",
            "pybind11-abi              4                    hd3eb1b0_1  \n",
            "pycodestyle               2.10.0          py311haa95532_0  \n",
            "pycosat                   0.6.4           py311h2bbff1b_0  \n",
            "pycparser                 2.21               pyhd3eb1b0_0  \n",
            "pyct                      0.5.0           py311haa95532_0  \n",
            "pycurl                    7.45.2          py311hcd4344a_0  \n",
            "pydispatcher              2.0.5           py311haa95532_2  \n",
            "pydocstyle                6.3.0           py311haa95532_0  \n",
            "pyerfa                    2.0.0           py311h2bbff1b_0  \n",
            "pyflakes                  3.0.1           py311haa95532_0  \n",
            "pygments                  2.15.1          py311haa95532_1  \n",
            "pyjwt                     2.4.0           py311haa95532_0  \n",
            "pylint                    2.16.2          py311haa95532_0  \n",
            "pylint-venv               2.3.0           py311haa95532_0  \n",
            "pyls-spyder               0.4.0              pyhd3eb1b0_0  \n",
            "pynacl                    1.5.0           py311h8cc25b3_0  \n",
            "pyodbc                    4.0.34          py311hd77b12b_0  \n",
            "pyopenssl                 23.2.0          py311haa95532_0  \n",
            "pyparsing                 3.0.9           py311haa95532_0  \n",
            "pyqt                      5.15.7          py311hd77b12b_0  \n",
            "pyqt5-sip                 12.11.0         py311hd77b12b_0  \n",
            "pyqtwebengine             5.15.7          py311hd77b12b_0  \n",
            "pyrsistent                0.18.0          py311h2bbff1b_0  \n",
            "pysocks                   1.7.1           py311haa95532_0  \n",
            "pytables                  3.8.0           py311ha4dc190_2  \n",
            "pytest                    7.4.0           py311haa95532_0  \n",
            "python                    3.11.4               h966fe2a_0  \n",
            "python-dateutil           2.8.2              pyhd3eb1b0_0  \n",
            "python-fastjsonschema     2.16.2          py311haa95532_0  \n",
            "python-json-logger        2.0.7           py311haa95532_0  \n",
            "python-libarchive-c       2.9                pyhd3eb1b0_1  \n",
            "python-lmdb               1.4.1           py311hd77b12b_0  \n",
            "python-lsp-black          1.2.1           py311haa95532_0  \n",
            "python-lsp-jsonrpc        1.0.0              pyhd3eb1b0_0  \n",
            "python-lsp-server         1.7.2           py311haa95532_0  \n",
            "python-slugify            5.0.2              pyhd3eb1b0_0  \n",
            "python-snappy             0.6.1           py311hd77b12b_0  \n",
            "pytoolconfig              1.2.5           py311haa95532_1  \n",
            "pytz                      2022.7          py311haa95532_0  \n",
            "pyviz_comms               2.3.0           py311haa95532_0  \n",
            "pywavelets                1.4.1           py311h2bbff1b_0  \n",
            "pywin32                   305             py311h2bbff1b_0  \n",
            "pywin32-ctypes            0.2.0           py311haa95532_1000  \n",
            "pywinpty                  2.0.10          py311h5da7b33_0  \n",
            "pyyaml                    6.0             py311h2bbff1b_1  \n",
            "pyzmq                     23.2.0          py311hd77b12b_0  \n",
            "qdarkstyle                3.0.2              pyhd3eb1b0_0  \n",
            "qstylizer                 0.2.2           py311haa95532_0  \n",
            "qt-main                   5.15.2               he8e5bd7_8  \n",
            "qt-webengine              5.15.9               hb9a9bb5_5  \n",
            "qtawesome                 1.2.2           py311haa95532_0  \n",
            "qtconsole                 5.4.2           py311haa95532_0  \n",
            "qtpy                      2.2.0           py311haa95532_0  \n",
            "qtwebkit                  5.212                h2bbfb41_5  \n",
            "queuelib                  1.5.0           py311haa95532_0  \n",
            "re2                       2022.04.01           hd77b12b_0  \n",
            "regex                     2022.7.9        py311h2bbff1b_0  \n",
            "reproc                    14.2.4               hd77b12b_1  \n",
            "reproc-cpp                14.2.4               hd77b12b_1  \n",
            "requests                  2.31.0          py311haa95532_0  \n",
            "requests-file             1.5.1              pyhd3eb1b0_0  \n",
            "requests-toolbelt         1.0.0           py311haa95532_0  \n",
            "rfc3339-validator         0.1.4           py311haa95532_0  \n",
            "rfc3986-validator         0.1.1           py311haa95532_0  \n",
            "rope                      1.7.0           py311haa95532_0  \n",
            "rtree                     1.0.1           py311h2eaa2aa_0  \n",
            "ruamel.yaml               0.17.21         py311h2bbff1b_0  \n",
            "ruamel_yaml               0.17.21         py311h2bbff1b_0  \n",
            "s3fs                      2023.3.0        py311haa95532_0  \n",
            "s3transfer                0.6.0           py311haa95532_0  \n",
            "sacremoses                0.0.43             pyhd3eb1b0_0  \n",
            "scikit-image              0.20.0          py311h3513d60_0  \n",
            "scikit-learn              1.3.0           py311hf62ec03_0  \n",
            "scikit-learn-intelex      2023.1.1        py311haa95532_0  \n",
            "scipy                     1.10.1          py311hc1ccb85_1  \n",
            "scrapy                    2.8.0           py311haa95532_0  \n",
            "seaborn                   0.12.2          py311haa95532_0  \n",
            "send2trash                1.8.0              pyhd3eb1b0_1  \n",
            "service_identity          18.1.0             pyhd3eb1b0_1  \n",
            "setuptools                68.0.0          py311haa95532_0  \n",
            "sip                       6.6.2           py311hd77b12b_0  \n",
            "six                       1.16.0             pyhd3eb1b0_1  \n",
            "smart_open                5.2.1           py311haa95532_0  \n",
            "snappy                    1.1.9                h6c2663c_0  \n",
            "sniffio                   1.2.0           py311haa95532_1  \n",
            "snowballstemmer           2.2.0              pyhd3eb1b0_0  \n",
            "sortedcontainers          2.4.0              pyhd3eb1b0_0  \n",
            "soupsieve                 2.4             py311haa95532_0  \n",
            "sphinx                    5.0.2           py311haa95532_0  \n",
            "sphinxcontrib-applehelp   1.0.2              pyhd3eb1b0_0  \n",
            "sphinxcontrib-devhelp     1.0.2              pyhd3eb1b0_0  \n",
            "sphinxcontrib-htmlhelp    2.0.0              pyhd3eb1b0_0  \n",
            "sphinxcontrib-jsmath      1.0.1              pyhd3eb1b0_0  \n",
            "sphinxcontrib-qthelp      1.0.3              pyhd3eb1b0_0  \n",
            "sphinxcontrib-serializinghtml 1.1.5              pyhd3eb1b0_0  \n",
            "spyder                    5.4.3           py311haa95532_1  \n",
            "spyder-kernels            2.4.3           py311haa95532_0  \n",
            "sqlalchemy                1.4.39          py311h2bbff1b_0  \n",
            "sqlite                    3.41.2               h2bbff1b_0  \n",
            "stack_data                0.2.0              pyhd3eb1b0_0  \n",
            "statsmodels               0.14.0          py311hd7041d2_0  \n",
            "sympy                     1.11.1          py311haa95532_0  \n",
            "tabulate                  0.8.10          py311haa95532_0  \n",
            "tbb                       2021.8.0             h59b6b97_0  \n",
            "tbb4py                    2021.8.0        py311h59b6b97_0  \n",
            "tblib                     1.7.0              pyhd3eb1b0_0  \n",
            "tenacity                  8.2.2           py311haa95532_0  \n",
            "terminado                 0.17.1          py311haa95532_0  \n",
            "text-unidecode            1.3                pyhd3eb1b0_0  \n",
            "textdistance              4.2.1              pyhd3eb1b0_0  \n",
            "threadpoolctl             2.2.0              pyh0d69192_0  \n",
            "three-merge               0.1.1              pyhd3eb1b0_0  \n",
            "tifffile                  2021.7.2           pyhd3eb1b0_2  \n",
            "tinycss2                  1.2.1           py311haa95532_0  \n",
            "tk                        8.6.12               h2bbff1b_0  \n",
            "tldextract                3.2.0              pyhd3eb1b0_0  \n",
            "toml                      0.10.2             pyhd3eb1b0_0  \n",
            "tomlkit                   0.11.1          py311haa95532_0  \n",
            "toolz                     0.12.0          py311haa95532_0  \n",
            "tornado                   6.3.2           py311h2bbff1b_0  \n",
            "tqdm                      4.65.0          py311h746a85d_0  \n",
            "traitlets                 5.7.1           py311haa95532_0  \n",
            "transformers              2.1.1              pyhd3eb1b0_0  \n",
            "twisted                   22.10.0         py311h2bbff1b_0  \n",
            "twisted-iocpsupport       1.0.2           py311h2bbff1b_0  \n",
            "typing-extensions         4.7.1           py311haa95532_0  \n",
            "typing_extensions         4.7.1           py311haa95532_0  \n",
            "tzdata                    2023c                h04d1e81_0  \n",
            "uc-micro-py               1.0.1           py311haa95532_0  \n",
            "ujson                     5.4.0           py311hd77b12b_0  \n",
            "unidecode                 1.2.0              pyhd3eb1b0_0  \n",
            "urllib3                   1.26.16         py311haa95532_0  \n",
            "utf8proc                  2.6.1                h2bbff1b_0  \n",
            "vc                        14.2                 h21ff451_1  \n",
            "vs2015_runtime            14.27.29016          h5e58377_2  \n",
            "w3lib                     1.21.0             pyhd3eb1b0_0  \n",
            "watchdog                  2.1.6           py311haa95532_0  \n",
            "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
            "webencodings              0.5.1           py311haa95532_1  \n",
            "websocket-client          0.58.0          py311haa95532_4  \n",
            "werkzeug                  2.2.3           py311haa95532_0  \n",
            "whatthepatch              1.0.2           py311haa95532_0  \n",
            "wheel                     0.38.4          py311haa95532_0  \n",
            "widgetsnbextension        4.0.5           py311haa95532_0  \n",
            "win_inet_pton             1.1.0           py311haa95532_0  \n",
            "winpty                    0.4.3                         4  \n",
            "wrapt                     1.14.1          py311h2bbff1b_0  \n",
            "xarray                    2023.6.0        py311haa95532_0  \n",
            "xlwings                   0.29.1          py311haa95532_0  \n",
            "xyzservices               2022.9.0        py311haa95532_1  \n",
            "xz                        5.4.2                h8cc25b3_0  \n",
            "y-py                      0.5.9           py311hb6bf4ef_0  \n",
            "yaml                      0.2.5                he774522_0  \n",
            "yaml-cpp                  0.7.0                hd77b12b_1  \n",
            "yapf                      0.31.0             pyhd3eb1b0_0  \n",
            "yarl                      1.8.1           py311h2bbff1b_0  \n",
            "ypy-websocket             0.8.2           py311haa95532_0  \n",
            "zeromq                    4.3.4                hd77b12b_0  \n",
            "zfp                       0.5.5                hd77b12b_6  \n",
            "zict                      2.2.0           py311haa95532_0  \n",
            "zipp                      3.11.0          py311haa95532_0  \n",
            "zlib                      1.2.13               h8cc25b3_0  \n",
            "zlib-ng                   2.0.7                h2bbff1b_0  \n",
            "zope                      1.0             py311haa95532_1  \n",
            "zope.interface            5.4.0           py311h2bbff1b_0  \n",
            "zstandard                 0.19.0          py311h2bbff1b_0  \n",
            "zstd                      1.5.5                hd43e919_0  \n"
          ]
        }
      ],
      "source": [
        "!conda list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8063beae",
      "metadata": {
        "id": "8063beae"
      },
      "outputs": [],
      "source": [
        "#Collaborative Filtering Implementation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8becd670",
      "metadata": {
        "id": "8becd670"
      },
      "outputs": [],
      "source": [
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import cross_validate, train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv(\"C:/Users/Joash/Desktop/recommender/train_normalized.csv\")\n",
        "\n",
        "# Prepare the dataset for Surprise\n",
        "reader = Reader(rating_scale=(train_data['target'].min(), train_data['target'].max()))\n",
        "data = Dataset.load_from_df(train_data[['customer_id', 'id', 'target']], reader)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use SVD algorithm\n",
        "model = SVD()\n",
        "\n",
        "# Train the model\n",
        "model.fit(trainset)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.test(testset)\n",
        "\n",
        "# Calculate and print RMSE\n",
        "accuracy = accuracy.rmse(predictions)\n",
        "print(f'RMSE: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54fec2d",
      "metadata": {
        "id": "a54fec2d"
      },
      "outputs": [],
      "source": [
        "#content based filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6958e3",
      "metadata": {
        "id": "3f6958e3",
        "outputId": "f565b2e6-1273-40f6-cd23-ade314e980e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some customer IDs from the dataset:\n",
            "['M758NNC' '2DRL5BC' 'RHBGFFN' 'CSK98OV' '15QGTMC' '2Y6FW6A' 'YOZ60T3'\n",
            " 'VCDRMET' '7JT1RT0' 'ZCFIWEA']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"C:/Users/Joash/Desktop/recommender/train_normalized.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few customer IDs\n",
        "print(\"Some customer IDs from the dataset:\")\n",
        "print(data['customer_id'].unique()[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8e8253",
      "metadata": {
        "id": "7c8e8253",
        "outputId": "8df87342-0a67-4468-9587-0448d696da82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  customer_id  location_number  latitude_x  longitude_x   id  latitude_y  \\\n",
            "0     M758NNC                1    0.696540     0.724165  274    0.010109   \n",
            "1     2DRL5BC                0    0.695719    -1.384726  221    0.008758   \n",
            "2     RHBGFFN                0    0.695934     0.716492   44    0.004109   \n",
            "3     CSK98OV                3    0.695175     0.701308  577    0.004986   \n",
            "4     15QGTMC                0    0.704267     0.666994   28    0.010956   \n",
            "5     2Y6FW6A                0    0.695791     0.706410   92    0.006255   \n",
            "6     YOZ60T3                0    0.696571    -1.389783   44    0.004109   \n",
            "7     VCDRMET                0    0.695029     0.703648  207    0.004107   \n",
            "8     7JT1RT0                0    0.695808     0.705758  196    0.000000   \n",
            "9     ZCFIWEA                0    0.695865     0.722382  288    0.005935   \n",
            "\n",
            "   longitude_y  vendor_rating  delivery_charge  serving_distance  ...  \\\n",
            "0     0.015505      -2.602839         0.796072          0.745516  ...   \n",
            "1     0.015324      -0.658965         0.796072          0.745516  ...   \n",
            "2     0.004724      -0.270190         0.796072          0.745516  ...   \n",
            "3     0.007831       0.507360         0.796072         -1.024065  ...   \n",
            "4     0.015340       0.118585         0.796072          0.745516  ...   \n",
            "5     0.019654       0.896134         0.796072         -1.529659  ...   \n",
            "6     0.004724      -0.270190         0.796072          0.745516  ...   \n",
            "7     0.004699      -1.047740         0.796072          0.745516  ...   \n",
            "8     0.003034       0.118585         0.796072         -0.518470  ...   \n",
            "9     0.019579       0.896134        -1.256168         -1.529659  ...   \n",
            "\n",
            "   vendor_tag_name_Free Delivery,Mexican,Salads  \\\n",
            "0                                             0   \n",
            "1                                             0   \n",
            "2                                             0   \n",
            "3                                             0   \n",
            "4                                             0   \n",
            "5                                             0   \n",
            "6                                             0   \n",
            "7                                             0   \n",
            "8                                             0   \n",
            "9                                             0   \n",
            "\n",
            "   vendor_tag_name_Fresh Juices,Healthy Food,Smoothies  \\\n",
            "0                                                  0     \n",
            "1                                                  1     \n",
            "2                                                  0     \n",
            "3                                                  0     \n",
            "4                                                  0     \n",
            "5                                                  0     \n",
            "6                                                  0     \n",
            "7                                                  0     \n",
            "8                                                  0     \n",
            "9                                                  0     \n",
            "\n",
            "   vendor_tag_name_Fresh Juices,Lebanese,Sandwiches,Shawarma  \\\n",
            "0                                                  0           \n",
            "1                                                  0           \n",
            "2                                                  0           \n",
            "3                                                  0           \n",
            "4                                                  0           \n",
            "5                                                  0           \n",
            "6                                                  0           \n",
            "7                                                  0           \n",
            "8                                                  0           \n",
            "9                                                  0           \n",
            "\n",
            "   vendor_tag_name_Fresh Juices,Milkshakes,Mojitos ,Sandwiches,Shawarma  \\\n",
            "0                                                  0                      \n",
            "1                                                  0                      \n",
            "2                                                  0                      \n",
            "3                                                  0                      \n",
            "4                                                  0                      \n",
            "5                                                  0                      \n",
            "6                                                  0                      \n",
            "7                                                  0                      \n",
            "8                                                  0                      \n",
            "9                                                  0                      \n",
            "\n",
            "   vendor_tag_name_Frozen yoghurt,Smoothies  \\\n",
            "0                                         0   \n",
            "1                                         0   \n",
            "2                                         0   \n",
            "3                                         0   \n",
            "4                                         0   \n",
            "5                                         0   \n",
            "6                                         0   \n",
            "7                                         0   \n",
            "8                                         0   \n",
            "9                                         0   \n",
            "\n",
            "   vendor_tag_name_Italian,Pasta,Pizzas,Salads,Sandwiches  \\\n",
            "0                                                  0        \n",
            "1                                                  0        \n",
            "2                                                  0        \n",
            "3                                                  0        \n",
            "4                                                  0        \n",
            "5                                                  0        \n",
            "6                                                  0        \n",
            "7                                                  0        \n",
            "8                                                  0        \n",
            "9                                                  0        \n",
            "\n",
            "   vendor_tag_name_Omani,Arabic,Shuwa,Pasta,Rice,Soups,Lebanese  \\\n",
            "0                                                  0              \n",
            "1                                                  0              \n",
            "2                                                  0              \n",
            "3                                                  0              \n",
            "4                                                  0              \n",
            "5                                                  0              \n",
            "6                                                  0              \n",
            "7                                                  0              \n",
            "8                                                  0              \n",
            "9                                                  0              \n",
            "\n",
            "   vendor_tag_name_Pizzas,Italian,Breakfast,Soups,Pasta,Salads,Desserts  \\\n",
            "0                                                  0                      \n",
            "1                                                  0                      \n",
            "2                                                  0                      \n",
            "3                                                  0                      \n",
            "4                                                  0                      \n",
            "5                                                  0                      \n",
            "6                                                  0                      \n",
            "7                                                  0                      \n",
            "8                                                  0                      \n",
            "9                                                  0                      \n",
            "\n",
            "   vendor_tag_name_Sandwiches,Breakfast,Burgers,Mojitos  \\\n",
            "0                                                  0      \n",
            "1                                                  0      \n",
            "2                                                  0      \n",
            "3                                                  0      \n",
            "4                                                  0      \n",
            "5                                                  0      \n",
            "6                                                  0      \n",
            "7                                                  0      \n",
            "8                                                  0      \n",
            "9                                                  0      \n",
            "\n",
            "   vendor_tag_name_Sandwiches,Shawarma,Fresh Juices,Mojitos,Milkshakes  \n",
            "0                                                  0                    \n",
            "1                                                  0                    \n",
            "2                                                  0                    \n",
            "3                                                  0                    \n",
            "4                                                  0                    \n",
            "5                                                  0                    \n",
            "6                                                  0                    \n",
            "7                                                  0                    \n",
            "8                                                  0                    \n",
            "9                                                  0                    \n",
            "\n",
            "[10 rows x 129 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Selecting relevant features\n",
        "    features = [\n",
        "        'distance_customer_to_restaurant', 'cuisine_diversity_score',\n",
        "        'uses_multiple_locations', 'multiple_orders_history',\n",
        "        'sunday_open_hours', 'monday_open_hours', 'tuesday_open_hours',\n",
        "        'wednesday_open_hours', 'thursday_open_hours', 'friday_open_hours',\n",
        "        'saturday_open_hours', 'latitude_x', 'longitude_x',\n",
        "        'latitude_y', 'longitude_y', 'vendor_rating',\n",
        "        'delivery_charge', 'serving_distance'\n",
        "    ]\n",
        "\n",
        "    # Assuming 'target' is the column to predict\n",
        "    X = data[features]\n",
        "    y = data['target']\n",
        "\n",
        "    # Scaling features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# Function for content-based filtering\n",
        "def content_based_filtering(user_id, data, X_scaled, top_n=10):\n",
        "    # Filter data for the specific user\n",
        "    user_data = data[data['customer_id'] == user_id]\n",
        "    user_index = user_data.index\n",
        "\n",
        "    # Calculate similarity\n",
        "    similarity_scores = cosine_similarity(X_scaled[user_index], X_scaled)\n",
        "\n",
        "    # Create a DataFrame for similarity scores\n",
        "    similarity_df = pd.DataFrame(similarity_scores, columns=data.index, index=user_index)\n",
        "\n",
        "    # Remove the user's own interactions\n",
        "    similarity_df = similarity_df.drop(user_index)\n",
        "\n",
        "    # Get top N similar items\n",
        "    top_items = similarity_df.mean().nlargest(top_n).index\n",
        "\n",
        "    return data.loc[top_items]\n",
        "\n",
        "# Load data\n",
        "file_path = \"C:/Users/Joash/Desktop/recommender/train_normalized.csv\"\n",
        "X_scaled, y = load_and_preprocess_data(file_path)\n",
        "\n",
        "# Load original data to get restaurant details\n",
        "original_data = pd.read_csv(file_path)\n",
        "\n",
        "# Example usage\n",
        "user_id = 'M758NNC'  # Example user ID (replace with a real ID from your dataset)\n",
        "recommended_items = content_based_filtering(user_id, original_data, X_scaled, top_n=10)\n",
        "print(recommended_items)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4e1838",
      "metadata": {
        "id": "be4e1838"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (surprise_env)",
      "language": "python",
      "name": "surprise_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}